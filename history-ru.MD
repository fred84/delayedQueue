## Введение

В прошлом проекте мне нужно было с увеличивающейся периодичностью выполнять какое-либо действие. Например узнавать статус платежа или перепослать непринятое уведомление. После анализа доступных решений мы взяли и написали свою маленькую библиотеку DELAYED_QUEUE на Java с использованием Redis в роли хранилища. 
В этой статье я расскажу: 
про ее возможности библиотеки
альтернативы
 и историю развития (или скорее список граблей, на которые мы по наивности наступили)


## Функционал

У нас есть обработчик определенного типа событий, мы можем сохранить событие с отложенным сроком исполнения и когда оно созреет, это событие будет доставлено обработчику. Если в процессе обработки произойдет будет выброшено исключение, то событие будет доставлено еще раз чуть позже (но не более максимального количества попыток)
Redis не дает гарантий сохраненности, к потере событий НУЖНО быть готовым, но в кластерном варианте показывает достаточно высокую надежность. Мы за 1.5 года эксплутации с этим ни разу не сталкивались

АПИ представлено всего несколькими методами

```
add handler
```

```
remove handler
```

```
enqueue with delay
```

Если вместе с событие надо передать контекст, то это делается через REACTOR_SUBSCRIBER_CONTEXT

```
add handler with context
```

```
enqueue with context
```

```
пример вывода
```

Создание сервиса можно сделать в "преднастроенном варианте"

```
короткий пример
```

Или можно сконфигурировать часть параметров

```
длинный пример с комментариями у каждой строки для чего это нужно
```

Потушить сервис (и все открытые подписки в redis) можно `service.close()` или через link:lifecycle `@predestroy`

С любой системой что-то может пойти не так, за ней надо отслеживать. В первую очередь будущих пользователей должны интересовать
Общий размер памяти, используемый редисом
Длины очередей событий, готовых к обработке ``` имя метрики ```


Как я уже упомянул, DELAYED_QUEUE написана на Java8 и тянет за собой только LETTUCE + JACKSON (и неявно PROJECT_REACTOR)


## История

Наш проект работал в AWS и разрабатывался и поддерживался всего 2 инженерами, так что добавлять в него требующие обслуживания компоненты мы посчитали нецелесообразным. Основным правилом было "бери компоненты managed by AWS", если это не стоит очень дорого.

Рассмотренные варианты

По этой причине сразу были исключены:
- Rabbit MQ (ссылка)
- JMS (тут честно сказать еще и опыта работы с ним не доставало)

Следующим мы исключили AWS SQS (ссылка), так как максимальное время задержки было всего 1 минута (проверить в документации)

Выбирая между реляционный БД и redis (обе managed by AWS) мы решили использовать последний, так как:
Нам не нужны были 100% гарантии, всегда есть резервный обход БД раз в сутки и повторное добавлению "зависших событий" в нашу очередь
По итогам 2 лет, я понимаю, что для объемов того проекта можно было использовать и БД, но дело уже сделано.

Забегая вперед, на тот момент уже как полгода существовал проект Netflix dynoqueue с примерно похожим принципом работы, но я к сожалению его тогда не нашел.

### Первая наивная реализация

Почитаю статей по организации очередей отложенных событий, мы остановились на на следующей структуре:
Событие добавляется в sorted_set (ссылка на описание), где весами выступает время ее будущего выполнения
По созреванию событие перекладывается из sorted_set в list (ccылка, фактически это просто queue) из которой обработчик вынимает событие

Упрощенный dispatcher для первого шага выглядел 

```
simple dispatcher
```

Обработчики вначале были сделаны через Spring Integration, что под капотом было просто 

```
redisClient.blockingRightPop(list_name)
```

Первые проблемы не заставили себя долго ждать

### Ненадежный dispatcher
Можно заметить, что в наивной реализации диспетчера операции добавления в list и удаления из sorted_set выполняются последовательно без обработки ошибок. Если при  добавлении в list произойдет ошибка (например отвалилось соединение), то событие безвозвратно утеряно. Благо redis поддерживает транзакции и мы стали их использовать

``` пример кода ```

### Ненадежный обработчик

Ровно такая же проблема подстерегала нас с другой стороны list-а. Если обработчик во время исполнения падал, то событие пропадало навсегда. Было решено при диспетчеризации вместо удаления элемента из sorted_set переписывать его на более позднее время и удалять только после успешного завершения обработчика.

https://bitbucket.org/hashconnecteu/cardprocessing/pull-requests/272#chg-src/main/java/com/walletone/gate/events/RedisEventService.java

``` пример кода ```

### Не уникальное событие
Как я уже упоминал, у нас изначально был запасной механизм, который обходил какую-нибудь табличку в БД и для объектов, которые долго висят в не конечном статусе, и повторно добавлял в нашу DELAYED_EVENTS событие. Так как события записывались у нас в sorted_set в виде
```metadata;payload```, где payload у нас неизменный, а вот metadata у следующей попытки для одного и того-же события отличалась. В итоге мы могли получить дубликат и много ненужных повторных попыток обработки. Эту ситуацию мы решили, вынеся и изменяемую metadata и неизменный payload в hset (ссылка). В итоге в ключе в sorted set остался только тип, идентификатор события
``` пример код ```

https://bitbucket.org/hashconnecteu/cardprocessing/pull-requests/278#chg-src/main/java/com/walletone/gate/events/RedisEventService.java

### Параллельный запуск диспетчера
Изначально мы писали все наши обработчики идемпотентными и не беспокоились о том, что событие может быть доставлено несколько раз. Такое могло случиться, если диспетчеры на разных экземплярах приложения запустились почти одновременно. Мелкое улучшение мы сделали, добавив попытку получения lock при запуске диспетчера и сохраняя его в тот же redis с коротким ttl

``` пример код ```

## Эволюция в отдельный проект

Когда отложенная очередь понадобилась в другом проекте без spring, то мы его вынесли в самостоятельную библиотеку. Под нож пошли зависимости от
Spring (заменили spring data на lettuce)
Spring integration (написали свой subscription для reactor)

Когда мы подумывали о замене spring integration (и исключении зависимости от спринга в целом), то решили попробовать сделать stream ```ссылка на hotstream``` поверх project reactor. Тут 

Второй пункт оказался достаточно трудоемким. Вместо spring int
https://bitbucket.org/hashconnecteu/cardprocessing/pull-requests/344


Зависающие подписки
https://github.com/fred84/delayedQueue/pull/15	

## Идеи на будущее

- kotlin suspend api
- sharding
- переделать 



## Заключение
На выходе мы получили библиотеку в push-стиле (в отличии от pull в netflix) где достаточно зарегистрировать подписчика на свое событие и больше ни о чем не думать (ну кроме мониторинга). В процессе написания и ранней эксплуатации мы исправили несколько глупых граблей и неожиданно узнали, что уже есть библиотека со схожим функционалом.
